The field of Artificial Intelligence is fundamentally about designing computer programs (called \textit{agents}) in an \textit{architecture} that they are empowered to make more complex decisions than what could be done before.
One such decision area considers planning a sequence of actions to achieve a predetermined goal.
Planning becomes more complex when the agent's environment changes, or when an agent's attempt to perform actions fails.
While many agent architectures have been proposed to accomplish this kind of task before, the Architecture for Intentional Agents ($\mathcal{AIA}$) seems most promising.
However, $\mathcal{AIA}$ has limitations in a desirable decision area: $\mathcal{AIA}$ is incapable of determining whether actions conform to rules (called \textit{policies}) provided by an external agent controller.
Policies can be expressed in $\mathcal{AOPL}$ as an allowance to perform an action (an \textit{authorization}) or a requirement to perform an action (an \textit{obligation}).
The work of this thesis proposal is to extend $\mathcal{AIA}$ such that it can reason over compliance for policies in $\mathcal{AOPL}$ and abide by compliant actions.
This extended architecture, called $\mathcal{APIA}$, will be evaluated by examples that demonstrate its policy compliance as well as evaluated by its runtime performance.
