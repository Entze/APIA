The field of artificial intelligence is fundamentally about designing computer programs (called \textit{agents}) in an \textit{architecture} that they are empowered to make more complex decisions than what could before.
One such decision area considers planning a sequence of actions to achieve a pre-determined goal.
Planning becomes more complex when the agent’s environment changes, or when an agent’s attempt to perform actions fail.
While many agent architectures have been proposed to accomplish this kind of task before, Architecture for Intentional Agents ($\mathcal{AIA}$) seems most promising.
However, $\mathcal{AIA}$ has limitations in a desirable decision area.
$\mathcal{AIA}$ is incapable of determining whether actions conform to rules (called \textit{policies}) provided by an external agent controller.
Policies can expressed in $\mathcal{AOPL}$ as an allowance to perform an action (an \textit{authorization}) or a requirement to perform an action (an \textit{obligation}).
The work of this thesis proposal is to extend $\mathcal{AIA}$ such that it can reason over policy compliance and abide to compliant actions.
The extended architecture, called $\mathcal{APIA}$, will be evaluated by examples that demonstrate its policy compliance and according to its run-time performance.
