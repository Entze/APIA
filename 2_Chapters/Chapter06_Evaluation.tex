\chapter{Evaluation}

% Use this chapter to describe the experiments you have run to validate your work.
% Describe the setup, show your data, and discuss the results.
%
% \section{Experimental Design}
%
% \section{Results}
%
% Tables are great for showing results, as seen in Table~\ref{tbl:Sample}.
%
% \begin{table}[ht]
%     \centering
%     \caption{Sample Table with Data}
%     \label{tbl:Sample}
%
%     \begin{tabular}{|l|c|c|}
%     \hline
%     \textbf{Column Title}             & \textbf{Column Title}       & \textbf{Column Title} \\ \hline
%     Row of Data                       & value                       & value                 \\ \hline
%     Row of Data                       & value                       & value                 \\ \hline
%     Row of Data                       & value                       & value                 \\ \hline
%     Row of Data                       & value                       & value                 \\ \hline
%     \end{tabular}
% \end{table}
%
% \section{Discussion}

\section{Runtime Performance Results}

\section{Conciseness}

Since our work on policy fluents and actions operate behind the scenes during the execution of an $\mathcal{APIA}$ agent, the conciseness and expressivity of user-defined encodings for this architecture are determined by the conciseness and expressivity of its underlying user-facing components: Action Language $\mathcal{AL}$ and Language $\mathcal{AOPL}$.

Action Language $\mathcal{AL}$ is a very concise method to represent complex transition systems.
To contrast, manually specifying a transition system would require enumerating all possible states and denoting which actions transition the world from each state to another state.
For example, our simplest example (Example A) has $309$ fluents and $71$ actions.
Though only $13$ are physical fluents and $20$ are physical actions, the user would have to enumerate $2^{13}$ states and then repeat them $2^{(309-13)}$ times for each possible mental and policy fluent value, leading to a grand total of $2^{309}$ states with $|\mathcal{P}(71)|=2^{71}$ compound actions to connect to each state.

In contrast, Example A utilizes $55$$\mathcal{AL}$ rules, only $9$ of which are user-defined (there are $37$ rules in the Theory of Intentions and $9$ in our policy compliance component).

A similar problem exists for $\mathcal{AOPL}$ policies.
Recall that an action can be permitted, not permitted, or not mentioned in an authorization policy as well as obligated to perform, obligated not to perform, or not mentioned in an obligation policy.
Given the non-contradiction axioms, there are $7$ valid combinations of $\mathcal{AOPL}$ policy statements (see \cref{table:apia_non_contradiction}).
Since $\mathcal{AOPL}$ compliance depends on the value of fluents within a state, each of the $2^{309}$ states must be annotated with the $\mathcal{AOPL}$ compliance value of all $71$ elementary actions.

In contrast, Example A utilizes $4$ $\mathcal{AOPL}$ policy statements.

\section{Expressivity}

Expressivity can take on two meanings.
On the one hand, it considers the extent to which statements resemble how one would naturally express their intention in English.
On the other hand, in the field of KRR, it also considers what kinds of knowledge can be represented by the expression.

Using the first definition, action language $\mathcal{AL}$ is also very expressive.
With the addition of a few words, an entire $\mathcal{AL}$ rule can be spoken in English.
For example, a dynamic causal law:
\begin{equation}
\begin{split}
    & move\_through(A, D) \textbf{ causes } in\_room(A, R_{2}) \textbf{ if} \\
    & in\_room(Actor, R_{1}), \\
    & door\_connects(D, R_{2}), \\
    & R_{2} \neq R_{1}
\end{split}
\end{equation}

For each atom, we place the first argument before the predicate name and the following arguments behind it.
For example, move\_through(A, D) becomes ``A move\_through D''.
Then, using the template:

``When actor <first argument of action> performs <action name> <remaining arguments of action>, it causes <first argument of effect> to be <effect name> <remaining arguments of effect> if <first argument of condition> <condition name> < remaining arguments of condition>''.

So, this rule can be read as ``When actor A performs move\_through D, it causes A to be in\_room R if A is in\_room $R_{1}$ and D connects $R_{2}$ and $R_{2}$ is not $R_{1}$.''

Likewise for static laws such as:
\begin{equation}
\begin{split}
    \neg in\_room(A, R_{2}) \textbf{ if } \
        & in\_room(A, R_{1}), \\
        & R_{2} \neq R_{1}
\end{split}
\end{equation}
we can use the following template:

``If <first argument of condition> is <condition name> < remaining arguments of condition>, then <first argument of fluent> is not <fluent name> <remaining arguments of fluent>''.

So, this static law would be read:

``If actor A is in room $R_{1}$ and $R_{1}$ is not $R_{2}$, then actor A is not in room $R_{2}$''.

Executability conditions have a similar reading.

In the case of $\mathcal{AOPL}$ policy statements:
\begin{equation}
    permitted(greet(A, P)) \textbf{ if }
        \neg busy\_working(P)
\end{equation}
is read ``The agent A is permitted to greet P if P is not busy working''

Defeasible statements are prefixed with ``normally''.

Likewise, obligation statements such as:
\begin{equation}
\begin{split}
    obl(\neg move(A, L)) \textbf{ if } \
        & location\_room(L, R), \\
        & room\_classified(R), \\
        & \neg has\_security\_clearance(A)
\end{split}
\end{equation}
are read ``the agent A is obligated not to move to L if location L is in room R, R is classified, and A does not have a security clearance.''

Since both $\mathcal{AL}$ and $\mathcal{AOPL}$ statements have straightforward translations to and from English, we believe these to be very readable and writable by other researchers with limited prior experience about these approaches.

Regarding the KRR definition of ``expressivity,'' we have a slightly different analysis.
An important feature to consider is the ability to reason over ``default'' logic.
Default logic considers rules that are ``normally'' true but may have exceptions.
Though language $\mathcal{AOPL}$ has this feature, action language $\mathcal{AL}$ does not.
By itself, this is an issue because our description of policy actions relies on this capability (non-compliant actions ``normally'' cause \neg auth_compliance(weak), but ignore_not_permitted(a) is an exception to this rule).
Fortunately for us, ASP (which $\mathcal{AL}$ rules are translated into) does have this limitation.
Thus, we use $\mathcal{AL}$-like rules in our action description of policy actions.

In the same vein, language $\mathcal{AOPL}$ also has a limitation (Note: $\mathcal{AL}$ also has this limitation, though we do not have any need to overcome it).
Given a rule:

\begin{equation}
    obl(a) \textbf{ if } cond
\end{equation}
$cond$ must be an expression of fluents.
Thus, it is possible to write a policy that applyes when another action is concurrently executed, such as ``an agent is obligated to take their ID badge with them when moving''.
Same as before, we bypass this limitation by utilizing the underlying flexibility of ASP (to which $\mathcal{AOPL}$ policy are translated) where we can use occurs in the rule body.

Another consideration of action language $\mathcal{AL}$ is that does not support so-called ``triggers'', in which a fluent can force an action to occur.
For example, when a door has an auto-locking timer, having door\_autolock\_countdown at zero could cause the lock\_door action.
This is not a limitation though, as we easily get around this by writing:
\begin{equation}
\begin{split}
    A \textbf{ causes } door_locked(L1, L2) \textbf{ if } \
        & physical_action(A) \\
        & door_autolock_countdown(L1, L2, T), \\
        & T = 1
\end{split}
\end{equation}
In this rule, all actions cause the door to lock when door\_autolock\_countdown is zero.
(One can consider the action causing the world to increment a timestep, which causes the door to lock).

\section{Elaboration Tolerance}

The elaboration tolerance of the $\mathcal{APIA}$ architecture can be assessed from a few different angles.

For example, one can assess the growth of the $\mathcal{AOPL}$ policy across increasingly more complex examples.
From Example A to Example D, only a few policy statements needed to be added or modified.
Though we could also discuss the elaboration tolerance of $\mathcal{AL}$, this is not relevant to this thesis.

The $\mathcal{APIA}$ architecture also provides a very easy way to construct agents with different policy-motivations.
By changing a command-line parameter and the input file of the agent's observations, one can easily construct different agents using the same knowledge base.

The policy actions of the $\mathcal{APIA}$ architecture also provide a very elaboration tolerant means of dismissing elements of user-defined $\mathcal{AOPL}$ policies.
In fact, they operate an arbitrary $\mathcal{AOPL}$ policies and do not require any changes to function correctly.

\section{Difficulty of Construction}

The difficulty of constructing the $\mathcal{APIA}$ architecture can be evaluated in three different areas: our reconstruction of the $\mathcal{AIA}$ architecture, our implementation of $\mathcal{AOPL}$ compliance, and our integration of $\mathcal{AOPL}$ into the $\mathcal{AIA}$ architecture.

Correctly constructing the logic program of the $\mathcal{AIA}$ architecture was very difficult.
Although copying the $\mathcal{AIA}$ ASP rules was straightforward, identifying transcription errors and typos (both on our end and in Blount's dissertation) was very time consuming.
In traditional programming languages, a programmer usually has a lot of information regarding the symptoms of a problem that allows him to quickly find the root cause.
Stack traces and step-through debuggers are examples.
Even in the worst case (such as a segmentation fault), a programmer can at least assume the approximate location of the error from the timing of the failure in its procedural execution.

None of these apply in an unsatisfiable ASP program.
Unfortunately, solvers such as \textsc{clingo} do not output a partial knowledge base or a statement denoting which rule caused the unsatisfiability.
During our implementation of the $\mathcal{AIA}$ logic program, we resorted to manually commenting out constraints and changing rule heads in order to restore satisfiability.
We then tested hypotheses of the root cause against this information in hopes of guessing correctly.

We used the same method in integrating $\mathcal{AOPL}$ compliance into the $\mathcal{AIA}$ intended action rules.
Through this process, we discovered the differences between observer-based $\mathcal{AOPL}$ compliance (as it was introduced by XXX) and agent-based $\mathcal{AOPL}$ compliance (for which we adjusted $\mathcal{AOPL}$ accordingly).

To assist in this process across control loop iterations, we created a collection of debugging tools and scripts that greatly improved our efficiency.
